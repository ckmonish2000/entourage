from .types import MessageRole, MessageRoleType, Usage
from datetime import datetime
from ..llm.client import LLMClient
from ..prompts.templates import compaction_prompt

class Conversation:
    def __init__(self, session_id:str, system_prompt):
        self.llm = LLMClient()
        self.token_usage = Usage(input_tokens=0, output_tokens=0, total_tokens=0)
        self.session_id = session_id
        self.tool_calls = []
        self.system_prompt = system_prompt
        self.messages = [
            {"session_id": session_id, "role": MessageRole.SYSTEM, "content": system_prompt, "createdAt": datetime.now()}
        ]
        self.compaction_history = []

    def add_message(self, role: MessageRoleType, content):
        message = {"session_id": self.session_id, "role": role, "content": content,"createdAt":datetime.now()}
        self.messages.append(message)

    def add_tool_call(self, tool_call):
        tool_call = {**tool_call, "session_id": self.session_id, "createdAt":datetime.now(), "role":"Function Call"}
        self.tool_calls.append(tool_call)

    def get_tool_by_id(self, tool_call_id):
        """Find a tool call by its call_id in the tracking list.

        Returns the index and tool call dict if found, otherwise (None, None).
        """
        for index, tool_call in enumerate(self.tool_calls):
            if tool_call['call_id'] == tool_call_id:
                return index, tool_call
        return None, None

    def update_tool_call(self, type, call_id, name, arguments={}, output=None):
        """Update or add a tool call entry in the tracking list.

        If a tool call with the given call_id exists, it's updated.
        Otherwise, a new entry is appended with session metadata.
        """
        index, tool_call = self.get_tool_by_id(call_id)
        tool_call_data = {
            "type": type,
            "call_id": call_id,
            "name": name,
            "arguments": arguments,
            "output": output,
            "session_id": self.session_id,
            "createdAt": datetime.now(),
            "role":"Function Call"
        }

        if index is not None:
            self.tool_calls[index] = tool_call_data
        else:
            self.tool_calls.append(tool_call_data)

    def get_messages(self):
        messages = []
        for msg in self.messages:
            messages.append({"role": msg["role"], "content": msg["content"]})
        return messages

    def get_history(self):
        """Return all messages and tool calls sorted by createdAt timestamp."""
        history = [*self.tool_calls, *self.messages]
        return sorted(history, key=lambda x: x.get('createdAt', datetime.min))

    def get_tool_calls(self):
        """Return all tool calls tracked in this conversation sorted by createdAt."""
        return sorted(self.tool_calls, key=lambda x: x.get('createdAt', datetime.min))

    def update_token_usage(self, usage:Usage):
        """Update token counts from API response"""
        self.token_usage = Usage(
            input_tokens=usage.input_tokens,
            output_tokens=usage.output_tokens,
            total_tokens=usage.total_tokens
        )
        return self.token_usage

    def get_token_usage(self):
        """Get current token usage"""
        return self.token_usage

    def needs_compaction(self, max_tokens, threshold=0.8):
          """Check if we've hit 80% threshold"""
          return self.token_usage['input_tokens'] >= (max_tokens * threshold)

    def compact(self):
        """Compact the conversation history by generating a summary and resetting arrays.

        This method:
        1. Collects all messages and tool calls (excluding system prompt)
        2. Generates a semantic summary using the LLM
        3. Stores compaction data in history for reference
        4. Resets messages and tool_calls arrays
        5. Re-adds system prompt with the compaction summary

        Returns:
            str: The compaction summary generated by the LLM
        """
        # Collect all conversations excluding system prompt
        conversations = [
            item for item in [*self.tool_calls, *self.messages]
            if item.get('role') != MessageRole.SYSTEM
        ]
        conversations = sorted(conversations, key=lambda x: x.get('createdAt', datetime.min))

        # Generate compaction summary
        prompt = compaction_prompt.replace("{conversation}", str(conversations))
        compacted_response = self.llm.generate(prompt=prompt)
        compaction_summary = getattr(compacted_response, 'output_text', str(compacted_response))

        # Store compaction data for historical reference
        compaction_data = {
            "session_id": self.session_id,
            "compacted_at": datetime.now(),
            "original_history": conversations,
            "summary": compaction_summary,
            "token_usage_before": {
                "input_tokens": self.token_usage['input_tokens'],
                "output_tokens": self.token_usage['output_tokens'],
                "total_tokens": self.token_usage['total_tokens']
            },
            "messages_count": len(self.messages),
            "tool_calls_count": len(self.tool_calls)
        }
        self.compaction_history.append(compaction_data)

        # Reset arrays - keep only system prompt with compaction context
        self.tool_calls = []
        self.messages = [
            {
                "session_id": self.session_id,
                "role": MessageRole.SYSTEM,
                "content": f"{self.system_prompt}\n\n## Previous Conversation Summary\n{compaction_summary}",
                "createdAt": datetime.now()
            }
        ]

        return compaction_summary

    def get_compaction_history(self):
        """Return the list of all compaction events that occurred in this conversation.

        Returns:
            list: List of compaction data dictionaries containing summaries and metadata
        """
        return self.compaction_history
